{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92c59a5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad727229",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[2], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[2], True)\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import matplotlib as mpl\n",
    "import imp\n",
    "mrsds = imp.load_source('mrsds', '/mnt/cup/people/orrenk/mrsds/mrsds-iclr/__init__.py')\n",
    "\n",
    "from mrsds import mrsds_switching_svae as mrsds\n",
    "from mrsds.mrsds_switching_svae import load_model\n",
    "from mrsds.utils_analysis import get_msgs_and_norms, get_communication_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f922f",
   "metadata": {},
   "source": [
    "#### Load mrsds model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805addd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/mnt/cup/people/orrenk/mrsds/mrsds-iclr/'\n",
    "model_dir = '/scratch/orrenk/testing/mika-6s_12_20210929-k2-d2-s-svae-test-models'\n",
    "config_path = base_dir + 'run-configs/mika-test.yaml'\n",
    "num_regions = 3\n",
    "num_dims = 2\n",
    "region_sizes = [121, 159, 220]\n",
    "trial_length = 184\n",
    "num_states = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3feade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s-svae multistep\n",
      "build model svae multitep mv\n",
      "model seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 18:05:58.782503: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 18:05:59.631075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4964 MB memory:  -> device: 2, name: GeForce RTX 2080 Ti, pci bus id: 0000:60:00.0, compute capability: 7.5\n",
      "/usr/people/orrenk/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.MultivariateNormalTriL_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xnets [<keras.engine.functional.Functional object at 0x7f54487a8be0>, <keras.engine.functional.Functional object at 0x7f54486a7190>] [<keras.engine.functional.Functional object at 0x7f54487a8e20>, <keras.engine.functional.Functional object at 0x7f5448699a00>]\n",
      "num_states 2\n",
      "transformer input shape 10 2\n",
      "[20, 10]\n",
      "[(None, 184, 10), (None, 184, 10), (None, 184, 10)] 2\n",
      "input shape (184, 32) 10 3 2\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 184, 32)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 184, 32)      64          input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 184, 32)      65532       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 184, 32)      0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_24 (TFOpLa (None, 184, 32)      0           dropout[0][0]                    \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 184, 32)      64          tf.__operators__.add_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 184, 10)      330         layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 184, 10)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 184, 32)      352         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_25 (TFOpLa (None, 184, 32)      0           conv1d_1[0][0]                   \n",
      "                                                                 tf.__operators__.add_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 184, 32)      64          tf.__operators__.add_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 184, 32)      65532       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 184, 32)      0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_26 (TFOpLa (None, 184, 32)      0           dropout_2[0][0]                  \n",
      "                                                                 tf.__operators__.add_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 184, 32)      64          tf.__operators__.add_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 184, 10)      330         layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 184, 10)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 184, 32)      352         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_27 (TFOpLa (None, 184, 32)      0           conv1d_3[0][0]                   \n",
      "                                                                 tf.__operators__.add_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 184, 45)      1485        tf.__operators__.add_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 184, 45)      0           dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 184, 8)       368         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 134,537\n",
      "Trainable params: 134,537\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "switching multistep\n",
      "masks none. null mask: (64, 184, 500) (64, 184, 500)\n",
      "WARNING:tensorflow:From /usr/people/orrenk/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:345: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "inf net time 0.36251330375671387\n",
      "inf time 0.37198400497436523\n",
      "rollout time 0.7132210731506348\n",
      "vec map xlik time 0.37467002868652344\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "xlik overshoot time 4.264814376831055\n",
      "xlik time 4.801507472991943\n",
      "lxmeans 10 11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "ylik time 1.0706026554107666\n",
      "us passed to ztransition.\n",
      "logpx_sum () Tensor(\"mul_81:0\", shape=(), dtype=float32)\n",
      "logpxy (64,) Tensor(\"Sum_49:0\", shape=(), dtype=float32)\n",
      "elbo () Tensor(\"sub_25:0\", shape=(), dtype=float32)\n",
      "Model: \"mrsds\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "continuous_state_transition_ multiple                  23220     \n",
      "_________________________________________________________________\n",
      "continuous_state_transition_ multiple                  23220     \n",
      "_________________________________________________________________\n",
      "discrete_state_transition (D multiple                  36        \n",
      "_________________________________________________________________\n",
      "gaussian_emissions (Gaussian multiple                  115188    \n",
      "_________________________________________________________________\n",
      "transformer_inference_networ multiple                  145227    \n",
      "=================================================================\n",
      "Total params: 283,685\n",
      "Trainable params: 283,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 18:06:09.005869: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "mrsds_model, xtran, _ = load_model(model_dir, config_path,\n",
    "                                   num_regions, num_dims,\n",
    "                                   region_sizes, trial_length,\n",
    "                                   num_states, load=True)\n",
    "\n",
    "# NOTE that in svae case that are two forms of the dynamics model\n",
    "# both have the same weights, but process inputs of size:\n",
    "# (batch, 1, latent_dims) and (batch, T, latent_dims) respectively.\n",
    "# The first is used for single timepoint rollouts used for forming\n",
    "# the structured posterior. The second is used to evaluate dynamics\n",
    "# on multiple timepoints in parallel.\n",
    "(xtran, xtran_time) = xtran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d42305",
   "metadata": {},
   "source": [
    "#### Load data from saved latents file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d74897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/scratch/orrenk/testing/mika-6s_12_20210929-k2-d2-s-svae-test_latents.mat'\n",
    "dat = loadmat(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcea392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__header__',\n",
       " '__version__',\n",
       " '__globals__',\n",
       " 'xs_train',\n",
       " 'xs_test',\n",
       " 'zs_train',\n",
       " 'zs_test',\n",
       " 'zs_logprob',\n",
       " 'zs_logprob_test',\n",
       " 'us_train',\n",
       " 'us_test',\n",
       " 'ys_train',\n",
       " 'ys_test',\n",
       " 'ys_recon_train',\n",
       " 'ys_recon_test',\n",
       " 'msgs_train',\n",
       " 'msgs_test',\n",
       " 'norms_train',\n",
       " 'norms_test',\n",
       " 'train_ids',\n",
       " 'test_ids',\n",
       " 'train_lengths',\n",
       " 'test_lengths',\n",
       " 'latent_region_sizes',\n",
       " 'loga_train',\n",
       " 'logb_train',\n",
       " 'loga_test',\n",
       " 'logb_test',\n",
       " 'elbos',\n",
       " 'lrs',\n",
       " 'log_pxs',\n",
       " 'log_pys',\n",
       " 'log_qxs',\n",
       " 'train_mses',\n",
       " 'train_r2s',\n",
       " 'train_gen1_mses',\n",
       " 'train_gen1_r2s',\n",
       " 'test_mses',\n",
       " 'test_r2s',\n",
       " 'test_gen1_mses',\n",
       " 'test_gen1_r2s',\n",
       " 'cosmooth_mses',\n",
       " 'cosmooth_r2s',\n",
       " 'cosmooth_gen1_mses',\n",
       " 'cosmooth_gen1_r2s']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dat.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b24be78",
   "metadata": {},
   "source": [
    "#### Run inference and get messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1260fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switching multistep\n",
      "masks none. null mask: (309, 184, 500) (309, 184, 500)\n",
      "inf net time 0.9694273471832275\n",
      "inf time 0.9714515209197998\n",
      "rollout time 10.333381414413452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 18:06:22.467750: I tensorflow/core/util/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x5654513a7830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec map xlik time 0.09164214134216309\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "us passed to ztransition.\n",
      "xlik overshoot time 0.9117112159729004\n",
      "xlik time 1.1586964130401611\n",
      "lxmeans 10 11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "ylik time 0.2512197494506836\n",
      "us passed to ztransition.\n",
      "logpx_sum () tf.Tensor(-5980400.5, shape=(), dtype=float32)\n",
      "logpxy (309,) tf.Tensor(-6033803000000.0, shape=(), dtype=float32)\n",
      "elbo () tf.Tensor(-19526926000.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "result_dict = mrsds_model(dat['ys_train'], dat['us_train'])\n",
    "\n",
    "input_len = dat['us_train'].shape[-1]\n",
    "\n",
    "# For padded trials of different lengths\n",
    "trial_lengths_train = dat['train_lengths'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73b2efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ys', 'us', 'zs_logprob', 'reconstructed_ys', 'log_py', 'logpy_sum', 'log_px', 'logpx_sum', 'log_py_cosmooth', 'z_posterior', 'z_posterior_ll', 'x_sampled', 'psi_sampled', 'xsample_prior', 'elbo', 'diffs_norm', 'sequence_likelihood', 'xt_entropy', 'log_a', 'log_b'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec8a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 184, 6) (309, 184, 2)\n"
     ]
    }
   ],
   "source": [
    "xs = result_dict['x_sampled'].numpy().squeeze()\n",
    "us = result_dict['us'].numpy()\n",
    "zs_logprob = result_dict['z_posterior_ll'].numpy()\n",
    "print(xs.shape, zs_logprob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a61a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "communication_models = get_communication_models(xtran_time,\n",
    "                                                num_regions=num_regions,\n",
    "                                                num_states=num_states,\n",
    "                                                input_len=input_len)\n",
    "latent_region_sizes = [num_dims]*num_regions\n",
    "msgs, norms = get_msgs_and_norms(communication_models,\n",
    "                                 xs, us, zs_logprob,\n",
    "                                 num_states=num_states,\n",
    "                                 num_regions=num_regions,\n",
    "                                 latent_dim=num_dims,\n",
    "                                 latent_region_sizes=latent_region_sizes,\n",
    "                                 trial_lengths=trial_lengths_train,\n",
    "                                 input_len=input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a2a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 184, 3, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "# Messages are of size:\n",
    "# (trials, time, num_regions, num_regions+num_inputs, latent_dim)\n",
    "print(msgs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
