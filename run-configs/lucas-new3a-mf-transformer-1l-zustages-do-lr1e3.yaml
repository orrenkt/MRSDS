
data:
  data_source: "lucas"
  trials: "all"  # alt: 'towers', 'visual'
  tlim: null  # reject trials over tlim timepoints
  inputs: 2     # 2 is default, will zero pad if not present
  stages: False #True not currently added in  # include trial stages as input
  history: False # include previous trial history
  hist_tlen: 0  # number of timepoints to include of previous trial 

model:
  uz: True  # pass inputs to discrete transition
  sz: True # pass stages to discrete transition
  xz: True  # pass continuous latents to discrete transition
  ux: True  # pass inputs to continuous transition 
  xic:
    layers: [8] # 2nd layer has var size
    activations: ["relu", null]
    triangular_cov: False  # NOTE these were added after first run.
    trainable_cov: True
  xtransition:
    triangular_cov: False
    trainable_cov: True
    zcond: False
    dynamics:
      communication_type: "additive" # alt "conditional"
      input_type: "additive" # alt "conditional"
      input_func_type: 'seperate' # alt: together
      layers: [32, 16] # 3rd layer has var size
      activations: ["relu", "relu", null]
    inputs:
      layers: [4, 2] # 3rd layer has var size
      activations: ["relu", "relu", null]
  emissions:
    triangular_cov: False
    trainable_cov: True
    dist: "gaussian"
    layers: [32, 32]
    activations: ["relu", "relu"]
    final_activation: null # poisson alt: exp, softplus

inference:
  triangular_cov: False
  trainable_cov: True
  embedding: 
    layers: [32, 10] #, [64, 32]
    activations: ["relu", "relu"]
  transformer: True
  transformer_params:
    head_size: 50
    num_heads: 10
    ff_dim: 8
    num_transformer_blocks: 2
    mlp_units: [45]
  xic_inf:
    layers: [32, null] # 2nd layer has var size
    activations: ["relu", null]
    xic_input_type: "hs"  # alt: ys, yes, hs for embeddings
    xic_input_len: -1  # alt: 25
  num_samples: 1  # number to use in evaluation
    
training:
  dynamics_only: True  # Continue training dynamics only
  smooth_coef: 0.1
  batch_size: 50 #64 #32
  xent: False 
  xent_init: 0
  xent_rate: 0.99
  xent_steps: 150
  xent_kickin_steps: 0
  xentropy_annealing: True
  flat_learning_rate: False
  use_inverse_annealing_lr: False
  num_steps: 3001 #5001
  num_steps_do: 5001 #7501 #5001
  learning_rate: 3.e-3
  lr_warmup_steps: 500
  lr_warmup_steps_do: 500 #1000
  beta_max: 1000.0
  beta_warmup_steps: 500
  temperature_annealing: True
  t_init: 0
  t_min: 1.0
  annealing_rate: 0.99
  annealing_steps: 550
  annealing_kickin_steps: 0
  log_steps: 200 #0  # when to print elbo and eval perf
  save_steps: 500 #500 #0 # when to checkpoint model, save progress
  dropout: True
  test_perc: 0.1
  drop_perc: 0.25
  dropout_trial_perc: 0.5
  num_samples: 1
